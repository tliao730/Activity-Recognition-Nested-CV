import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFECV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

class ModelEvaluator:
    def __init__(self, feature_extractor):
        """
        Args:
            feature_extractor: ä½ çš„ FeatExtrac å¯¦ä¾‹ï¼Œç”¨ä¾†ç²å–è³‡æ–™ã€‚
        """
        self.fe = feature_extractor

    def nested_logistic_regression_eval(self, df_full_train, n_splits=5, solver='liblinear', max_iter=500):
        """
        ä½¿ç”¨å·¢ç‹€äº¤å‰é©—è­‰ä¾†å…¬å¹³è©•ä¼° RFECV é¸å‡ºçš„ç‰¹å¾µé›†ã€‚
        """
        X_full = df_full_train.drop(columns='label').copy()
        y_full = df_full_train['label'].copy()
        
        outer_validator = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=77)
        
        outer_test_scores = []
        optimal_features_per_fold = []
        inner_rfecv_scores = [] 
        all_optimal_features = []

        # Outer CV loop
        for train_index, test_index in outer_validator.split(X_full, y_full):
            X_train_raw, X_test_raw = X_full.iloc[train_index], X_full.iloc[test_index]
            y_train, y_test = y_full.iloc[train_index], y_full.iloc[test_index]

            # --- é—œéµä¿®æ­£ï¼šæ¨™æº–åŒ– (Standardization) ---
            # å¿…é ˆåœ¨æ¯ä¸€æŠ˜å…§ç¨ç«‹é€²è¡Œï¼Œä¸”æ¸¬è©¦é›†åªèƒ½ç”¨è¨“ç·´é›†çš„åƒæ•¸é€²è¡Œ transform
            scaler = StandardScaler()
            X_train = pd.DataFrame(scaler.fit_transform(X_train_raw), columns=X_train_raw.columns)
            X_test = pd.DataFrame(scaler.transform(X_test_raw), columns=X_test_raw.columns)

            # Inner CV: ç”¨æ–¼é¸æ“‡ç‰¹å¾µ
            inner_validator = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)
            model = LogisticRegression(solver=solver, max_iter=max_iter)
            
            # ä½¿ç”¨ RFECV è‡ªå‹•é¸æ“‡æœ€ä½³ç‰¹å¾µæ•¸é‡
            selector = RFECV(estimator=model, cv=inner_validator, scoring='accuracy', n_jobs=-1)
            selector.fit(X_train, y_train)
            
            # è¨˜éŒ„é€™ä¸€æŠ˜çš„æœ€ä½³ç‰¹å¾µ
            optimal_features = X_train.columns[selector.support_]
            all_optimal_features.append(optimal_features.tolist())
            
            # ä½¿ç”¨é¸å‡ºçš„ç‰¹å¾µåœ¨ Outer Test ä¸Šé€²è¡Œå…¬å¹³è©•ä¼°
            final_model = LogisticRegression(solver=solver, max_iter=max_iter)
            final_model.fit(X_train[optimal_features], y_train)
            
            y_pred = final_model.predict(X_test[optimal_features])
            outer_test_scores.append(accuracy_score(y_test, y_pred))
            optimal_features_per_fold.append(selector.n_features_)
            inner_rfecv_scores.append(selector.cv_results_['mean_test_score'].max())

        return {
            'mean_outer_acc': np.mean(outer_test_scores),
            'mean_opt_p': np.mean(optimal_features_per_fold),
            'mean_inner_acc': np.mean(inner_rfecv_scores),
            'features_sets': all_optimal_features
        }

    def run_l_segment_experiment(self, max_l=20, n_splits_outer=5):
        """
        éæ­·ä¸åŒçš„æ™‚çª—åˆ†å‰²å€¼ (l)ï¼Œå°‹æ‰¾æœ€ä½³çµ„åˆã€‚
        """
        results = []

        for seg in range(1, max_l + 1):
            print(f"ğŸ”„ æ­£åœ¨è™•ç† l = {seg}...")
            # å¾ä½ çš„ç‰¹å¾µæå–æ¨¡çµ„ç²å–è³‡æ–™
            df_train = self.fe.get_features(data_type='train', l=seg)

            res = self.nested_logistic_regression_eval(
                df_train, n_splits=n_splits_outer
            )
            
            results.append({
                'Split (l)': seg,
                'Num of Features (p)': round(res['mean_opt_p']),
                'Accuracy (Outer CV)': round(res['mean_outer_acc'], 4),
                'Accuracy (Inner RFECV)': round(res['mean_inner_acc'], 4)
            })

        results_df = pd.DataFrame(results)
        return results_df

# --- åŸ·è¡Œç¯„ä¾‹ ---
if __name__ == "__main__":
    from feature_extraction import FeatExtrac # å‡è¨­ä½ çš„æå–æ¨¡çµ„æª”å
    
    # 1. åˆå§‹åŒ–
    fe = FeatExtrac("../data/AReM")
    evaluator = ModelEvaluator(fe)
    
    # 2. åŸ·è¡Œå¯¦é©— (ç‚ºäº†ç¤ºç¯„å…ˆè·‘ l=1~5)
    report_df = evaluator.run_l_segment_experiment(max_l=5)
    
    # 3. è¼¸å‡ºçµæœ
    print("\n" + "="*50)
    print("ğŸ“‹ é‚è¼¯è¿´æ­¸å¯¦é©—å ±å‘Š")
    print("="*50)
    print(report_df)
    
    # 4. æ‰¾å‡ºæœ€ä½³çµ„åˆ
    best_idx = report_df['Accuracy (Outer CV)'].idxmax()
    best = report_df.loc[best_idx]
    print(f"\næœ€ä½³ (l*, p*) çµ„åˆ:")
    print(f"æ™‚çª—åˆ†å‰² (l) = {int(best['Split (l)'])}")
    print(f"ç‰¹å¾µæ•¸é‡ (p) â‰ˆ {int(best['Num of Features (p)'])}")
    print(f"æ¸¬è©¦æº–ç¢ºç‡ = {best['Accuracy (Outer CV)']}")